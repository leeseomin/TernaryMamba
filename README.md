# TernaryMamba: 
A ternary quantized language model based on the Mamba architecture, enabling model compression and efficient inference by representing weights as {-1, 0, 1}.

<br><br>
## dependency

 pip install mamba-ssm causal-conv1d



## run
<br>

ğŸŸ§ ```b158_mamba_v2.py```  : ê¸°ë³¸ BitNet-b1.58-mamba   : í˜„ì¬ê¹Œì§€ ì¶”ì²œ 

ğŸŸ§ ```b158_mamba_v2a.py```  : ê¸°ë³¸ BitNet-b1.58-mamba   : í˜„ì¬ê¹Œì§€ ì¶”ì²œ + safetensorë¡œ ì €ì¥í•˜ê¸° ì¶”ê°€ 

ğŸŸ§ ```b158_mamba_v3.py```  : ê¸°ë³¸ BitNet-b1.58-mamba   : í˜„ì¬ê¹Œì§€ ì¶”ì²œ  + Shakespeare ì§ì ë‹¤ìš´í›„ì— ì§„í–‰ 
<br>


ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ OpenWebTextÂ ë‹¤ìš´ë¡œë“œí›„  1/10 ë§Œ í›ˆë ¨, ëŒ€ëµ 1.7GB ì˜ train ë°ì´í„°ì…‹ (ë¦¬ì†ŒìŠ¤ì œí•œë“±) 

ğŸŸ§ ```mamba_OpenWeb_colab-v10.ipynb```  : ê¸°ë³¸ mamba  colabìš©    : 

ğŸŸ§ ```b158_mamba_OpenWeb_colab-v10.ipynb```  : ê¸°ë³¸ BitNet-b1.58-mamba  colabìš©    : í˜„ì¬ê¹Œì§€ ì¶”ì²œ,  a100,v100 ë“± ì¶”ì²œ  25g vram ì‚¬ìš© , loss ê·¸ë˜í”„ ë‚˜ì˜´ 

ğŸ’™ğŸ’™ ê²°ê³¼ 




ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ OpenWebTextÂ ë‹¤ìš´ë¡œë“œí›„  5/10 ë§Œ í›ˆë ¨, ëŒ€ëµ 8.5GB ì˜ train ë°ì´í„°ì…‹ (ë¦¬ì†ŒìŠ¤ì œí•œë“±) í•´ë³´ê¸° 















```b158_mamba_v6.py``` : ê¸°ë³¸ BitNet-b1.58-mamba + Straight-Through Estimator (STE) ê¸°ë²•ì¶”ê°€ : ëŒë ¤ë³´ë‹ˆ ë¹„ì¶”í•˜ëŠ” ê¸°ë²•

ë‹¤ë§Œ STEëŠ” í¸í–¥(bias)ì´ ìˆëŠ” ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì •ì¹˜ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ì´ë¡œ ì¸í•œ ìˆ˜ë ´ ì†ë„ ì €í•˜ë‚˜ ìˆ˜ë ´ ì•ˆì •ì„± ì €í•˜ ë“±ì˜ ì ì¬ì  ë¬¸ì œì ì´ ìˆìŒì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤. ë”°ë¼ì„œ Mamba ëª¨ë¸ì— STEë¥¼ ì ìš©í•  ê²½ìš° ì„¸ì‹¬í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ê³¼ ëª¨ë‹ˆí„°ë§ì´ í•„ìš”í•  ê²ƒì…ë‹ˆë‹¤.



