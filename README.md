# TernaryMamba: 
A ternary quantized language model based on the Mamba architecture, enabling model compression and efficient inference by representing weights as {-1, 0, 1}.


### Ternary Quantization
The model's weights are quantized to three values: {-1, 0, 1}. This enables model compression and efficient inference by representing the weights in a compact form.

### Mamba Architecture
The language model is constructed using Mamba blocks, which consist of:
- LayerNorm
- SwiGLU (Swish activation + Gated Linear Unit)
- Mamba State Space Model (SSM)

### OpenWebText Dataset
- The model is trained on 30~50% of the OpenWebText dataset.
- The data is preprocessed and stored in binary format, which is loaded during training.

### Model Training
- The model is trained using the Adam optimizer.
- During the training process:
  - Train/val losses are periodically evaluated.
  - The loss graph is updated.

<br><br>
## dependency

 pip install mamba-ssm causal-conv1d



## run
<br>


ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§  ë¡œì»¬ UBUNTU TESTED,   rtx 4090, TernaryMamba   =  OpenWebTextÂ ë‹¤ìš´ë¡œë“œí›„  3/10 ë§Œ í›ˆë ¨, ëŒ€ëµ 5GB ì˜ train ë°ì´í„°ì…‹ 

ğŸŸ§ ```python MAIN/local_r2_TernaryMamba_32_30_layer10_embed512``` 

ğŸ’™ğŸ’™ ê²°ê³¼ 



ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ colab a100, OpenWebTextÂ ë‹¤ìš´ë¡œë“œí›„  50%  ë§Œ í›ˆë ¨

```colab_TernaryMamba_data50.ipynb```





ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ğŸŸ§ OpenWebTextÂ ë‹¤ìš´ë¡œë“œí›„  4/10 ë§Œ í›ˆë ¨, ëŒ€ëµ 6.8GB ì˜ train ë°ì´í„°ì…‹ (ë¦¬ì†ŒìŠ¤ì œí•œë“±) í•´ë³´ê¸° 


ğŸŸ§ ```TernaryMamba_local-v10-5.py```  : ë¡œì»¬ BitNet-b1.58-mamba   rtx4090ìš© ë²„ì „ vram 24g  : batch 64-> 32    : í…ŒìŠ¤íŒ…ì¤‘ , killed , colabì—ì„œ í•´ì•¼? ë°°ì¹˜ì‹¸ì´ì¦ˆ 32ë¡œ í•˜ê³ ?  ì‹¤íŒ¨


ğŸŸ§ ```TernaryMamba_colab-v10-4.ipynb```  :  ê¸°ë³¸ BitNet-b1.58-mamba  colabìš©  :::ë°°ì¹˜ì‹¸ì´ì¦ˆ 32      ,      í…ŒìŠ¤íŒ…ì¤‘

















